{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51703d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30ed74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Kidney-Disease-Classification-Deep-Learning-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffcba35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca46b685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Kidney-Disease-Classification-Deep-Learning-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670476c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "370a88f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"e:\\Conda\\envs\\nncls\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24812\\1895252374.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\__init__.py\", line 468, in <module>\n",
      "    importlib.import_module(\"keras.src.optimizers\")\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\__init__.py\", line 7, in <module>\n",
      "    from keras import _tf_keras as _tf_keras\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\_tf_keras\\__init__.py\", line 1, in <module>\n",
      "    from keras._tf_keras import keras\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py\", line 7, in <module>\n",
      "    from keras import activations as activations\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\activations\\__init__.py\", line 7, in <module>\n",
      "    from keras.src.activations import deserialize as deserialize\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\__init__.py\", line 8, in <module>\n",
      "    from keras.src import models\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\models\\__init__.py\", line 1, in <module>\n",
      "    from keras.src.models.functional import Functional\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 16, in <module>\n",
      "    from keras.src.models.model import Model\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\models\\model.py\", line 14, in <module>\n",
      "    from keras.src.trainers import trainer as base_trainer\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 14, in <module>\n",
      "    from keras.src.trainers.data_adapters import data_adapter_utils\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\__init__.py\", line 4, in <module>\n",
      "    from keras.src.trainers.data_adapters import array_data_adapter\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py\", line 7, in <module>\n",
      "    from keras.src.trainers.data_adapters import array_slicing\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_slicing.py\", line 12, in <module>\n",
      "    import pandas\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pandas\\__init__.py\", line 38, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pandas\\compat\\__init__.py\", line 29, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"e:\\Conda\\envs\\nncls\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24812\\1895252374.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\__init__.py\", line 468, in <module>\n",
      "    importlib.import_module(\"keras.src.optimizers\")\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\__init__.py\", line 7, in <module>\n",
      "    from keras import _tf_keras as _tf_keras\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\_tf_keras\\__init__.py\", line 1, in <module>\n",
      "    from keras._tf_keras import keras\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py\", line 7, in <module>\n",
      "    from keras import activations as activations\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\activations\\__init__.py\", line 7, in <module>\n",
      "    from keras.src.activations import deserialize as deserialize\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\__init__.py\", line 8, in <module>\n",
      "    from keras.src import models\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\models\\__init__.py\", line 1, in <module>\n",
      "    from keras.src.models.functional import Functional\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 16, in <module>\n",
      "    from keras.src.models.model import Model\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\models\\model.py\", line 14, in <module>\n",
      "    from keras.src.trainers import trainer as base_trainer\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 14, in <module>\n",
      "    from keras.src.trainers.data_adapters import data_adapter_utils\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\__init__.py\", line 4, in <module>\n",
      "    from keras.src.trainers.data_adapters import array_data_adapter\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py\", line 7, in <module>\n",
      "    from keras.src.trainers.data_adapters import array_slicing\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_slicing.py\", line 12, in <module>\n",
      "    import pandas\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"e:\\Conda\\envs\\nncls\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24812\\1895252374.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\__init__.py\", line 468, in <module>\n",
      "    importlib.import_module(\"keras.src.optimizers\")\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\__init__.py\", line 7, in <module>\n",
      "    from keras import _tf_keras as _tf_keras\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\_tf_keras\\__init__.py\", line 1, in <module>\n",
      "    from keras._tf_keras import keras\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py\", line 29, in <module>\n",
      "    from keras import wrappers as wrappers\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\wrappers\\__init__.py\", line 7, in <module>\n",
      "    from keras.src.wrappers.sklearn_wrapper import (\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\wrappers\\__init__.py\", line 1, in <module>\n",
      "    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\wrappers\\sklearn_wrapper.py\", line 8, in <module>\n",
      "    from keras.src.wrappers.fixes import _routing_enabled\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\wrappers\\fixes.py\", line 2, in <module>\n",
      "    import sklearn\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 9, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 20, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 421, in <module>\n",
      "    import pyarrow\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"e:\\Conda\\envs\\nncls\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24812\\1895252374.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\__init__.py\", line 468, in <module>\n",
      "    importlib.import_module(\"keras.src.optimizers\")\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\__init__.py\", line 7, in <module>\n",
      "    from keras import _tf_keras as _tf_keras\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\_tf_keras\\__init__.py\", line 1, in <module>\n",
      "    from keras._tf_keras import keras\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py\", line 29, in <module>\n",
      "    from keras import wrappers as wrappers\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\wrappers\\__init__.py\", line 7, in <module>\n",
      "    from keras.src.wrappers.sklearn_wrapper import (\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\wrappers\\__init__.py\", line 1, in <module>\n",
      "    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\wrappers\\sklearn_wrapper.py\", line 11, in <module>\n",
      "    from keras.src.wrappers.utils import TargetReshaper\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\wrappers\\utils.py\", line 4, in <module>\n",
      "    import sklearn\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\base.py\", line 20, in <module>\n",
      "    from .utils._missing import is_scalar_nan\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 9, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 20, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 421, in <module>\n",
      "    import pyarrow\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"e:\\Conda\\envs\\nncls\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24812\\1895252374.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\__init__.py\", line 468, in <module>\n",
      "    importlib.import_module(\"keras.src.optimizers\")\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\__init__.py\", line 7, in <module>\n",
      "    from keras import _tf_keras as _tf_keras\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\_tf_keras\\__init__.py\", line 1, in <module>\n",
      "    from keras._tf_keras import keras\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py\", line 29, in <module>\n",
      "    from keras import wrappers as wrappers\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\wrappers\\__init__.py\", line 7, in <module>\n",
      "    from keras.src.wrappers.sklearn_wrapper import (\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\wrappers\\__init__.py\", line 1, in <module>\n",
      "    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\wrappers\\sklearn_wrapper.py\", line 16, in <module>\n",
      "    import sklearn\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\base.py\", line 20, in <module>\n",
      "    from .utils._missing import is_scalar_nan\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 9, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 20, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 421, in <module>\n",
      "    import pyarrow\n",
      "  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0eab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"kidney-ct-scan-image\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fcb820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ab6897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        # 1. Reconstruct Architecture\n",
    "        base_model = tf.keras.applications.vgg16.VGG16(\n",
    "            input_shape=self.config.params_image_size,\n",
    "            weights=None, \n",
    "            include_top=False\n",
    "        )\n",
    "        \n",
    "        # 2. Add custom layers\n",
    "        x = tf.keras.layers.Flatten()(base_model.output)\n",
    "        \n",
    "        # CHANGE THIS LINE: \n",
    "        # Your saved model was trained on 2 classes, so this MUST be 2.\n",
    "        classes = 2 \n",
    "        \n",
    "        prediction = tf.keras.layers.Dense(\n",
    "            units=classes,\n",
    "            activation=\"softmax\"\n",
    "        )(x)\n",
    "        \n",
    "        # 3. Assemble\n",
    "        self.model = tf.keras.models.Model(inputs=base_model.input, outputs=prediction)\n",
    "        \n",
    "        # 4. Load weights\n",
    "        # This will now work because the shapes match (25088, 2) == (25088, 2)\n",
    "        self.model.load_weights(self.config.updated_base_model_path)\n",
    "        print(f\"Success! Model loaded with {classes} classes.\")\n",
    "    def train_valid_generator(self):\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        # Convert Path object to string for Keras compatibility\n",
    "        model.save(str(path))\n",
    "\n",
    "    def train(self):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), # Add your preferred optimizer\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b65688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-20 20:52:25,668: INFO: common: yaml file: E:\\Kidney-Disease-Classification-Deep-Learning-Project\\config\\config.yaml loaded successfully]\n",
      "[2026-01-20 20:52:25,686: INFO: common: yaml file: E:\\Kidney-Disease-Classification-Deep-Learning-Project\\params.yaml loaded successfully]\n",
      "[2026-01-20 20:52:25,688: INFO: common: created directory at: artifacts]\n",
      "[2026-01-20 20:52:25,690: INFO: common: created directory at: artifacts\\training]\n",
      "Success! Model loaded with 2 classes.\n",
      "Found 93 images belonging to 2 classes.\n",
      "Found 372 images belonging to 2 classes.\n",
      "Epoch 1/200\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 6s/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.6000 - val_loss: nan\n",
      "Epoch 2/200\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 6s/step - accuracy: 0.5000 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 306ms/step - accuracy: 0.5000 - loss: nan - val_accuracy: 0.6000 - val_loss: nan\n",
      "Epoch 3/200\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - accuracy: 0.5140 - loss: nan - val_accuracy: 0.6000 - val_loss: nan\n",
      "Epoch 4/200\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 300ms/step - accuracy: 0.5625 - loss: nan - val_accuracy: 0.6000 - val_loss: nan\n",
      "Epoch 5/200\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 6s/step - accuracy: 0.5169 - loss: nan - val_accuracy: 0.6000 - val_loss: nan\n",
      "Epoch 6/200\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 5s/step - accuracy: 0.5000 - loss: nan"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nFileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\\\data_ingestion\\\\kidney-ct-scan-image\\\\Normal\\\\Normal- (637).jpg'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py\", line 264, in _finite_generator\n    yield self._standardize_batch(self.py_dataset[i])\n\n  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py\", line 71, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py\", line 316, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\utils\\image_utils.py\", line 235, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\\\data_ingestion\\\\kidney-ct-scan-image\\\\Normal\\\\Normal- (637).jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_multi_step_on_iterator_4432]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     training\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     training\u001b[38;5;241m.\u001b[39mget_base_model()\n\u001b[0;32m      6\u001b[0m     training\u001b[38;5;241m.\u001b[39mtrain_valid_generator()\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[10], line 93\u001b[0m, in \u001b[0;36mTraining.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_generator\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_generator\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     88\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m), \u001b[38;5;66;03m# Add your preferred optimizer\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(),\n\u001b[0;32m     90\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     91\u001b[0m )\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(\n\u001b[0;32m    102\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrained_model_path,\n\u001b[0;32m    103\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    104\u001b[0m )\n",
      "File \u001b[1;32me:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nFileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\\\data_ingestion\\\\kidney-ct-scan-image\\\\Normal\\\\Normal- (637).jpg'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py\", line 264, in _finite_generator\n    yield self._standardize_batch(self.py_dataset[i])\n\n  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py\", line 71, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py\", line 316, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"e:\\Conda\\envs\\nncls\\lib\\site-packages\\keras\\src\\utils\\image_utils.py\", line 235, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\\\data_ingestion\\\\kidney-ct-scan-image\\\\Normal\\\\Normal- (637).jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_multi_step_on_iterator_4432]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b316b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nncls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
